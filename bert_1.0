{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f1119de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "332b8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32e57c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7df7f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cointegrated/rubert-tiny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30c90749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=312, padding='max_length')\n",
    "\n",
    "\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMOPQRSTUVWXYZ<>^[-]()_%*\"\"\\\\\\n'\n",
    "num = '0123456789'\n",
    "def clear_words(sent):\n",
    "    new_sent = sent\n",
    "    for i in new_sent:\n",
    "        if i in alphabet:\n",
    "            new_sent = new_sent.replace(i, '')\n",
    "        elif i in num:\n",
    "            return ''\n",
    "    if len(new_sent) == 0:\n",
    "        return ''\n",
    "    if new_sent[0] == ' ':\n",
    "        return new_sent[1:] \n",
    "    else:\n",
    "        return new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d471aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('anekdot.json', encoding=\"utf-8\") as f:\n",
    "    anecdot = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa264368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6516c2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "for i in range(len(anecdot)):\n",
    "    text_list.append(anecdot[i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb362ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be069fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = [item for sentence in text_list for item in sentence.split('.') if item != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbe59b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = list(filter(lambda x: x != '\\n', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fe2150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = []\n",
    "for temp in word:\n",
    "    if len(temp) > 8:\n",
    "        new_temp = clear_words(temp)\n",
    "        if new_temp != '':\n",
    "            new_words.append(new_temp)\n",
    "word = new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5522eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_anecdot, test_anecdot = train_test_split(word, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a6d7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dd = Dataset.from_dict({'text': train_anecdot})\n",
    "test_dd = Dataset.from_dict({'text': test_anecdot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77502561",
   "metadata": {},
   "outputs": [],
   "source": [
    "anecdot_dd = datasets.DatasetDict({'train': train_dd, 'test': test_dd})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e890d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28814204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef72aa1552a4d7dbef6bb5945b4d76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989c42ae77ca46fe9d3cb9c117e74c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_anecdot = anecdot_dd.map(start_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ae77d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb798caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(example):\n",
    "    example['labels'] = example['input_ids'].copy()\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f38e1a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739726cfc5e849e7a3d528ee4fd81d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2aad00481354e7e888c6dc90bae493d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_anecdot = tokenizer_anecdot.map(labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "461dc910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "972e4b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29564, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 312)\n",
       "      (token_type_embeddings): Embedding(2, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "        (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=312, out_features=29564, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "985c7912",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='D:/Anecdote_BERT/',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.001\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenizer_anecdot[\"train\"],\n",
    "    eval_dataset=tokenizer_anecdot[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fe00b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b410bd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   47005 KB |   47005 KB |   47005 KB |       0 B  |\\n|       from large pool |   36864 KB |   36864 KB |   36864 KB |       0 B  |\\n|       from small pool |   10141 KB |   10141 KB |   10141 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   47005 KB |   47005 KB |   47005 KB |       0 B  |\\n|       from large pool |   36864 KB |   36864 KB |   36864 KB |       0 B  |\\n|       from small pool |   10141 KB |   10141 KB |   10141 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   49152 KB |   49152 KB |   49152 KB |       0 B  |\\n|       from large pool |   36864 KB |   36864 KB |   36864 KB |       0 B  |\\n|       from small pool |   12288 KB |   12288 KB |   12288 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |    2147 KB |    2652 KB |    9059 KB |    6912 KB |\\n|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |\\n|       from small pool |    2147 KB |    2652 KB |    9059 KB |    6912 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |      60    |      60    |      60    |       0    |\\n|       from large pool |       1    |       1    |       1    |       0    |\\n|       from small pool |      59    |      59    |      59    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |      60    |      60    |      60    |       0    |\\n|       from large pool |       1    |       1    |       1    |       0    |\\n|       from small pool |      59    |      59    |      59    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       7    |       7    |       7    |       0    |\\n|       from large pool |       1    |       1    |       1    |       0    |\\n|       from small pool |       6    |       6    |       6    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       6    |       6    |       6    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       6    |       6    |       6    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5a6554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 183378\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 91690\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='91690' max='91690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [91690/91690 2:25:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.525400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-1000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-1000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-1500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-1500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-2000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-2000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-2500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-2500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-2500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-3000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-3000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-3000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-3500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-3500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-3500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-4000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-4000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-4500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-4500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-4500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-5000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-5000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-5000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-5500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-5500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-5500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-6000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-6000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-6500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-6500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-6500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-7000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-7000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-7000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-7500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-7500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-7500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-8000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-8000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-8500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-8500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-8500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-9000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-9000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-9000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-9500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-9500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-9500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-10000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-10000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-10500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-10500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-10500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-11000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-11000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-11000\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-11500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-11500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-11500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-12000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-12000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-12000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-12500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-12500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-12500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-12500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-12500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-13000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-13000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-13000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-13000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-13000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-13500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-13500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-13500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-13500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-13500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-14000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-14000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-14000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-14000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-14000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-14500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-14500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-14500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-14500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-14500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-15000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-15000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-15000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-15000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-15000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-15500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-15500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-15500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-15500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-15500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-16000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-16000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-16000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-16000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-16000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-16500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-16500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-16500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-16500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-16500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-17000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-17000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-17000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-17000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-17000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-17500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-17500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-17500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-17500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-17500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-18000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-18000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-18000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-18000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-18000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-18500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-18500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-18500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-18500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-18500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-19000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-19000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-19000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-19000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-19000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-19500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-19500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-19500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-19500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-19500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-20000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-20000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-20500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-20500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-20500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-20500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-20500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-21000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-21000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-21000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-21000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-21000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-21500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-21500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-21500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-21500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-21500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-22000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-22000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-22000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-22000\\tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-22000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-22500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-22500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-22500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-22500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-22500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-23000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-23000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-23000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-23000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-23000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-23500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-23500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-23500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-23500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-23500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-24000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-24000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-24000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-24000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-24000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-24500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-24500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-24500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-24500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-24500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-25000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-25000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-25000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-25000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-25000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-25500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-25500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-25500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-25500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-25500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-26000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-26000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-26000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-26000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-26000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-26500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-26500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-26500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-26500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-26500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-27000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-27000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-27000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-27000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-27000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-27500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-27500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-27500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-27500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-27500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-28000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-28000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-28000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-28000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-28000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-28500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-28500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-28500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-28500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-28500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-29000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-29000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-29000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-29000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-29000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-29500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-29500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-29500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-29500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-29500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-30000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-30000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-30000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-30500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-30500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-30500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-30500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-30500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-31000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-31000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-31000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-31000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-31000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-31500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-31500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-31500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-31500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-31500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-32000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-32000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-32000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-32000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-32000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-32500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-32500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-32500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-32500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-32500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-33000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-33000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-33000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-33000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-33000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-33500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-33500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-33500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-33500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-33500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-34000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-34000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-34000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-34000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-34000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-34500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-34500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-34500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-34500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-34500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-35000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-35000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-35000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-35000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-35000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-35500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-35500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-35500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-35500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-35500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-36000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-36000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-36000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-36000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-36000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-36500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-36500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-36500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-36500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-36500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-37000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-37000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-37000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-37000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-37000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-37500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-37500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-37500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-37500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-37500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-38000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-38000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-38000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-38000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-38000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-38500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-38500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-38500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-38500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-38500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-39000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-39000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-39000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-39000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-39000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-39500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-39500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-39500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-39500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-39500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-40000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-40000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-40000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-40000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-40000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-40500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-40500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-40500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-40500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-40500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-41000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-41000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-41000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-41000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-41000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-41500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-41500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-41500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-41500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-41500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-42000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-42000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-42000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-42000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-42000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-42500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-42500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-42500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-42500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-42500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-43000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-43000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-43000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-43000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-43000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-43500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-43500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-43500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-43500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-43500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-44000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in D:/Anecdote_BERT/checkpoint-44000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-44000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-44000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-44000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-44500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-44500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-44500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-44500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-44500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-45000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-45000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-45000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-45000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-45000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-45500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-45500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-45500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-45500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-45500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-46000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-46000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-46000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-46000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-46000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-46500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-46500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-46500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-46500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-46500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-47000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-47000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-47000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-47000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-47000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-47500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-47500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-47500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-47500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-47500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-48000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-48000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-48000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-48000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-48000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-48500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-48500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-48500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-48500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-48500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-49000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-49000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-49000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-49000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-49000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-49500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-49500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-49500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-49500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-49500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-50000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-50000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-50000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-50000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-50000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-50500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-50500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-50500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-50500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-50500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-51000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-51000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-51000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-51000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-51000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-51500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-51500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-51500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-51500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-51500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-52000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-52000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-52000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-52000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-52000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-52500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-52500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-52500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-52500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-52500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-53000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-53000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-53000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-53000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-53000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-53500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-53500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-53500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-53500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-53500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-54000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-54000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-54000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-54000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-54000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-54500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-54500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-54500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-54500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-54500\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-55000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-55000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-55000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-55000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-55000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-55500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-55500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-55500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-55500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-55500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-56000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-56000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-56000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-56000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-56000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-56500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-56500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-56500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-56500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-56500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-57000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-57000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-57000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-57000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-57000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-57500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-57500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-57500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-57500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-57500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-58000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-58000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-58000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-58000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-58000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-58500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-58500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-58500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-58500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-58500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-59000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-59000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-59000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-59000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-59000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-59500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-59500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-59500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-59500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-59500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-60000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-60000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-60000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-60000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-60000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-60500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-60500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-60500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-60500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-60500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-61000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-61000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-61000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-61000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-61000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-61500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-61500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-61500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-61500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-61500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-62000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-62000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-62000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-62000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-62000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-62500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-62500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-62500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-62500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-62500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-63000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-63000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-63000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-63000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-63000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-63500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-63500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-63500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-63500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-63500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-64000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-64000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-64000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-64000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-64000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-64500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-64500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-64500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-64500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-64500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-65000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-65000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-65000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-65000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-65000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-65500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-65500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-65500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-65500\\tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-65500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-66000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-66000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-66000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-66000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-66000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-66500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-66500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-66500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-66500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-66500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-67000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-67000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-67000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-67000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-67000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-67500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-67500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-67500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-67500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-67500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-68000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-68000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-68000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-68000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-68000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-68500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-68500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-68500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-68500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-68500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-69000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-69000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-69000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-69000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-69000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-69500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-69500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-69500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-69500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-69500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-70000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-70000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-70000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-70000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-70000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-70500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-70500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-70500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-70500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-70500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-71000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-71000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-71000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-71000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-71000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-71500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-71500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-71500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-71500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-71500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-72000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-72000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-72000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-72000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-72000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-72500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-72500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-72500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-72500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-72500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-73000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-73000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-73000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-73000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-73000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-73500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-73500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-73500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-73500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-73500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-74000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-74000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-74000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-74000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-74000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-74500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-74500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-74500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-74500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-74500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-75000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-75000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-75000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-75000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-75000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-75500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-75500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-75500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-75500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-75500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-76000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-76000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-76000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-76000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-76000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-76500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-76500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-76500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-76500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-76500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-77000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-77000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-77000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-77000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-77000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-77500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-77500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-77500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-77500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-77500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-78000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-78000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-78000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-78000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-78000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-78500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-78500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-78500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-78500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-78500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-79000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-79000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-79000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-79000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-79000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-79500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-79500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-79500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-79500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-79500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-80000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-80000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-80000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-80000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-80000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-80500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-80500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-80500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-80500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-80500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-81000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-81000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-81000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-81000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-81000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-81500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-81500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-81500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-81500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-81500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-82000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-82000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-82000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-82000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-82000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-82500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-82500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-82500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-82500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-82500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-83000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-83000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-83000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-83000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-83000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-83500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-83500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-83500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-83500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-83500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-84000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-84000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-84000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-84000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-84000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-84500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-84500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-84500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-84500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-84500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-85000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-85000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-85000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-85000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-85000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-85500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-85500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-85500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-85500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-85500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-86000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-86000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-86000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-86000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-86000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-86500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-86500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-86500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-86500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-86500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-87000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-87000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-87000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-87000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-87000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-87500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in D:/Anecdote_BERT/checkpoint-87500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-87500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-87500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-87500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-88000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-88000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-88000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-88000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-88000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-88500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-88500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-88500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-88500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-88500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-89000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-89000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-89000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-89000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-89000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-89500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-89500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-89500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-89500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-89500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-90000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-90000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-90000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-90000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-90000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-90500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-90500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-90500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-90500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-90500\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-91000\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-91000\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-91000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-91000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-91000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/Anecdote_BERT/checkpoint-91500\n",
      "Configuration saved in D:/Anecdote_BERT/checkpoint-91500\\config.json\n",
      "Model weights saved in D:/Anecdote_BERT/checkpoint-91500\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/Anecdote_BERT/checkpoint-91500\\tokenizer_config.json\n",
      "Special tokens file saved in D:/Anecdote_BERT/checkpoint-91500\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=91690, training_loss=0.013797058608070102, metrics={'train_runtime': 8715.0428, 'train_samples_per_second': 42.083, 'train_steps_per_second': 10.521, 'total_flos': 1668372105104640.0, 'train_loss': 0.013797058608070102, 'epoch': 2.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbf2c841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./bert_model\n",
      "Configuration saved in ./bert_model\\config.json\n",
      "Model weights saved in ./bert_model\\pytorch_model.bin\n",
      "tokenizer config file saved in ./bert_model\\tokenizer_config.json\n",
      "Special tokens file saved in ./bert_model\\special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('./bert_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1145ae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./bert_model\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./bert_model\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 600,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 29564\n",
      "}\n",
      "\n",
      "loading weights file ./bert_model\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at ./bert_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
      "loading configuration file https://huggingface.co/cointegrated/rubert-tiny/resolve/main/config.json from cache at C:\\Users\\danch/.cache\\huggingface\\transformers\\d9b64e1a24a590ee04161821000abd8b25f6d111e31c013f8016ae9403385b31.fb42ff637f72882f9aa6f1883cdb8ee9e6ba319eadc2daed4f887496cce58ec6\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"cointegrated/rubert-tiny\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 600,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 29564\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/cointegrated/rubert-tiny/resolve/main/vocab.txt from cache at C:\\Users\\danch/.cache\\huggingface\\transformers\\3fed67599ef8853982f9c746f1783fd75ee0e95a64dfb29ed57865001438c7ed.77a9cd5f52c58bd231a1d3bc7390917dc6d0fadc0f17cee179994e8dfe382aba\n",
      "loading file https://huggingface.co/cointegrated/rubert-tiny/resolve/main/tokenizer.json from cache at C:\\Users\\danch/.cache\\huggingface\\transformers\\93d19392b8bd4b67bac7f021ae9a66566e2d9fce258a91eff120750506446f41.a5902d04b644b38f072d27ead4d54ae75995f94fa8752f130da31b8acf145bc0\n",
      "loading file https://huggingface.co/cointegrated/rubert-tiny/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/cointegrated/rubert-tiny/resolve/main/special_tokens_map.json from cache at C:\\Users\\danch/.cache\\huggingface\\transformers\\11065a2b44d83dc39a7b738b75d18d462970e31000f2562f21ee587eca67a88b.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/cointegrated/rubert-tiny/resolve/main/tokenizer_config.json from cache at C:\\Users\\danch/.cache\\huggingface\\transformers\\94137cff5a9cb3618ba6fccc7d68bb96d9d2d967d38189bd477843664cb37c65.fe75a54220b67b5c6b8a8ff559b6a8d9e8dc294a08351bab039fb65e3af43319\n",
      "loading configuration file https://huggingface.co/cointegrated/rubert-tiny/resolve/main/config.json from cache at C:\\Users\\danch/.cache\\huggingface\\transformers\\d9b64e1a24a590ee04161821000abd8b25f6d111e31c013f8016ae9403385b31.fb42ff637f72882f9aa6f1883cdb8ee9e6ba319eadc2daed4f887496cce58ec6\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"cointegrated/rubert-tiny\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 600,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 29564\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9996341466903687,\n",
       "  'token': 0,\n",
       "  'token_str': '[PAD]',\n",
       "  'sequence': ''},\n",
       " {'score': 0.0003227947745472193,\n",
       "  'token': 2,\n",
       "  'token_str': '[CLS]',\n",
       "  'sequence': ''},\n",
       " {'score': 4.289035473448166e-07,\n",
       "  'token': 17076,\n",
       "  'token_str': 'живи',\n",
       "  'sequence': 'живи'},\n",
       " {'score': 3.689229401970806e-07,\n",
       "  'token': 3,\n",
       "  'token_str': '[SEP]',\n",
       "  'sequence': ''},\n",
       " {'score': 3.1906310482554545e-07,\n",
       "  'token': 26148,\n",
       "  'token_str': 'Кога',\n",
       "  'sequence': 'Кога'},\n",
       " {'score': 2.9207816965026723e-07,\n",
       "  'token': 151,\n",
       "  'token_str': 'ã',\n",
       "  'sequence': 'ã'},\n",
       " {'score': 1.7393743689808616e-07,\n",
       "  'token': 447,\n",
       "  'token_str': '⋅',\n",
       "  'sequence': '⋅'},\n",
       " {'score': 1.511834710754556e-07,\n",
       "  'token': 10637,\n",
       "  'token_str': 'Tonight',\n",
       "  'sequence': 'Tonight'},\n",
       " {'score': 1.4786564861424267e-07,\n",
       "  'token': 24345,\n",
       "  'token_str': 'Wicked',\n",
       "  'sequence': 'Wicked'},\n",
       " {'score': 1.4076242393912253e-07,\n",
       "  'token': 12779,\n",
       "  'token_str': 'добре',\n",
       "  'sequence': 'добре'},\n",
       " {'score': 1.4049740570953873e-07,\n",
       "  'token': 435,\n",
       "  'token_str': '√',\n",
       "  'sequence': '√'},\n",
       " {'score': 1.249826624416528e-07,\n",
       "  'token': 29313,\n",
       "  'token_str': '##гнём',\n",
       "  'sequence': '##гнём'},\n",
       " {'score': 1.1728904070196222e-07,\n",
       "  'token': 26884,\n",
       "  'token_str': '##рдын',\n",
       "  'sequence': '##рдын'},\n",
       " {'score': 1.1365528251872092e-07,\n",
       "  'token': 433,\n",
       "  'token_str': '∗',\n",
       "  'sequence': '∗'},\n",
       " {'score': 1.1288960166666584e-07,\n",
       "  'token': 434,\n",
       "  'token_str': '∙',\n",
       "  'sequence': '∙'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = AutoModelForMaskedLM.from_pretrained('./bert_model', local_files_only=True)\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=bert_model,\n",
    "    tokenizer=model_name,\n",
    "    top_k=15\n",
    ")\n",
    "fill_mask('[MASK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094069d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
